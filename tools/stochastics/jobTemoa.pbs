#! /bin/bash

# This is a simple job submission script that can be adapted for your needs.
# At the very least, change the name of the program (line 10), 
# number of nodes requested (line 16) and 
# wallclock time requested (line 19) and
# your program arguments (line 48)

# Name of the program (used to produce standard output and error logs - Eg. test.o### )
#PBS -N test
# Combine both error and output logs
#PBS -j oe

# Change nodes as desired below
# ppn refers to processes per node which is usually equal to number of cores (32 in our case)
#PBS -l nodes=2:ppn=32

# Wall clock time limit in hh:mm:ss format
#PBS -l walltime=72:00:00

# Available queues are short (5 min), low, medium and high priority.
# medium is appropriate for most users
#PBS -q long 

# If you wish to export environment variables, use both lines below
#PBS -V
# Just note that HYDRA_HOST_FILE shouldn't be set in this environment
unset HYDRA_HOST_FILE

# If you wish to receive email,  update email and 
# remove first '#' from line below
# #PBS -M username@ncsu.edu
   # a  mail is sent when the job is aborted by the batch system.
   # b  mail is sent when the job begins execution.
   # e  mail is sent when the job terminates.
#PBS -m abe

# Change to the program's directory
cd /home/arqueiroz/temoa/stochastic/usdatabase_64n
echo "Directory: $PBS_O_WORKDIR"
date
echo "Number of nodes is ${PBS_NUM_NODES}"
echo "Number of cores is ${PBS_NP}"
# If you wish to print the nodes on which your program ran, uncomment line below
# cat $PBS_NODEFILE

# TODO: Replace cpi with your program and arguments
#mpiexec -n $PBS_NP -machinefile $PBS_NODEFILE ./cpi
export PYRO_NS_PORT=9096
#mpiexec -n $PBS_NP -machinefile $PBS_NODEFILE \ 
#-np 1 /home/arqueiroz/anaconda2/bin/pyomo_ns : \
#-np 1 /home/arqueiroz/anaconda2/bin/dispatch_srvr : \
#-np 3 /home/arqueiroz/anaconda2/bin/phsolverserver : \
#-np 1 /home/arqueiroz/anaconda2/bin/runph --solver=cplex --solver-manager=phpyro --shutdown-pyro -m models -i scenariodata --default-rho=1.0
mpiexec -np 1 /home/arqueiroz/anaconda2/bin/pyomo_ns -n localhost : -np 1 /home/arqueiroz/anaconda2/bin/dispatch_srvr localhost : -np 3 /home/arqueiroz/anaconda2/bin/phsolverserver : -np 1 /home/arqueiroz/anaconda2/bin/runph --solver=cplex --solver-manager=phpyro --shutdown-pyro --traceback -m ../../temoa_model/ -i ./ --default-rho=1

# mpiexec can detect number of available cores by default
# So above is equivalent to line below. But use the detailed version above, as that
# explicitly identifies number of cores etc.
# mpiexec ./cpi

